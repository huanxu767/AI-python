{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T03:49:41.650972Z",
     "start_time": "2024-05-03T03:49:40.200022Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toad\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "target = 'target'\n",
    "to_drop = []\n",
    "train_date = ['202210', '202211', '202212']\n",
    "oot_date = ['202301']\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/apple/Desktop/target2.csv')\n",
    "data['target'] = data['target'].replace({'good': 0, 'bad': 1})\n",
    "data = data.drop(columns = to_drop)\n",
    "\n",
    "data['fill_bill_date'] = data['fill_bill_date'].astype(str)\n",
    "data['dep_prov_no'] = data['dep_prov_no'].astype(str)\n",
    "data['usr_job'] = data['usr_job'].astype(str)\n",
    "data['schooling'] = data['schooling'].astype(str)\n",
    "data = data[data['dep_prov_no'] == '22']\n",
    "\n",
    "columns = list(data.columns)\n",
    "columns[:-1] = ['X_' + str(i+1) for i in range(len(data.columns)-1)]\n",
    "data.columns = columns\n",
    "\n",
    "\n",
    "train_data = data[data['X_1'].isin(train_date)]\n",
    "oot_data = data[data['X_1'].isin(oot_date)]\n",
    "train_data = train_data.drop(columns = ['X_1','X_4'])\n",
    "oot_data = oot_data.drop(columns = ['X_1','X_4'])\n",
    "\n",
    "# 将数据分割成训练集的比例\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(train_data, test_size=0.2, random_state=55,stratify=train_data[target])\n",
    "# train_data.shape,oot_data.shape\n",
    "# toad.detect(train_set)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T03:49:44.718999Z",
     "start_time": "2024-05-03T03:49:41.671972Z"
    }
   },
   "id": "c8d5329a7543db37",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:51:24.909841Z",
     "start_time": "2024-05-03T03:51:24.840816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_selected, dropped = toad.selection.drop_empty(train_set,threshold = 0.8, return_drop=True)\n",
    "print('删除缺失值多的变量-后',train_selected.shape)\n",
    "train_selected.head(3)\n",
    "# \n",
    "# train_selected, dropped = toad.selection.drop_iv(train_selected,threshold = 0.1,return_drop=True)\n",
    "# print('删除低iv的变量-后',train_selected.shape)\n",
    "# \n",
    "# train_selected, dropped = toad.selection.drop_corr(train_selected,target = target,threshold = 0.7, return_drop=True)\n",
    "# print('删除相关性高的变量-后',train_selected.shape)\n",
    "# 训练集\n",
    "\n",
    "train_set_X = train_selected.drop(columns=target)\n",
    "train_set_Y = train_selected[target]\n",
    "\n",
    "test_set_X = test_set[train_set_X.columns]\n",
    "test_set_Y = test_set[target]\n",
    "\n",
    "oot_set_X = oot_data[train_set_X.columns]\n",
    "oot_set_Y = oot_data[target]"
   ],
   "id": "6fbea604aa2a7de7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除缺失值多的变量-后 (25711, 148)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:54:34.173132Z",
     "start_time": "2024-05-03T03:54:34.041950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one-hot 转换\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "processed_train_data = preprocessor.fit_transform(train_set_X)\n",
    "processed_test_data = preprocessor.fit_transform(test_set_X)\n",
    "processed_oot_data = preprocessor.fit_transform(oot_set_X)\n",
    "\n",
    "print(processed_train_data.shape, processed_test_data.shape, processed_oot_data.shape)\n",
    "# 获取转换后的特征名称\n",
    "columns = preprocessor.get_feature_names_out()\n",
    "# 创建新的DataFrame，使用新的列名\n",
    "onehot_train_X = pd.DataFrame(processed_train_data, columns=columns)\n",
    "onehot_test_X = pd.DataFrame(processed_train_data, columns=columns)\n",
    "onehot_oot_X = pd.DataFrame(processed_train_data, columns=columns)\n",
    "print(onehot_train_X.shape, onehot_test_X.shape, onehot_oot_X.shape)\n"
   ],
   "id": "c0d1cf890b69ad6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25711, 174) (6428, 174) (9361, 174)\n",
      "(25711, 174) (25711, 174) (25711, 174)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除缺失值多的变量-后 (25711, 148)\n",
      "8632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25711, 8632), (6428, 8632), (9361, 8632))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": [
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "# 拟合编码器到训练数据\n",
    "encoder.fit(train_set_X)\n",
    "\n",
    "# 转换训练数据和测试数据\n",
    "onehot_train_X = encoder.transform(train_set_X)\n",
    "onehot_test_X = encoder.transform(test_set_X)\n",
    "onehot_oot_X = encoder.transform(oot_set_X)\n",
    "\n",
    "# onehot_train_X.shape,onehot_test_X.shape,onehot_oot_X.shape\n",
    "# 获取列名\n",
    "columns = encoder.get_feature_names_out(input_features=train_set_X.columns)\n",
    "\n",
    "# 转换为DataFrame并设置列名\n",
    "onehot_train_X = pd.DataFrame(onehot_train_X, columns=columns)\n",
    "onehot_test_X = pd.DataFrame(onehot_test_X, columns=columns)\n",
    "onehot_oot_X = pd.DataFrame(onehot_oot_X, columns=columns)\n",
    "print(len(columns))\n",
    "# columns\n",
    "# onehot_train_X_df.head(10)\n",
    "onehot_train_X.shape,onehot_test_X.shape,onehot_oot_X.shape"
   ],
   "id": "e194676ec0c677b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:24:47.393440Z",
     "start_time": "2024-05-01T04:23:18.230972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb = XGB(\n",
    "    colsample_bytree= 0.8,\n",
    "    learning_rate= 0.1,\n",
    "    max_depth= 4,\n",
    "    n_estimators= 100,\n",
    "    subsample= 0.8,\n",
    "    seed=11\n",
    ")\n",
    "\n",
    "xgb.fit(onehot_train_X,train_set_Y)\n",
    "\n",
    "xgb_predict_proba = xgb.predict_proba(onehot_train_X)\n",
    "\n",
    "xgb_def_rate = xgb_predict_proba[:,1]"
   ],
   "id": "f8f1b89f07e78292",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Booster.__del__ at 0x14eb1a840>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 1651, in __del__\n",
      "    def __del__(self) -> None:\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function DMatrix.__del__ at 0x14eb18b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 797, in __del__\n",
      "    _check_call(_LIB.XGDMatrixFree(self.handle))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m xgb \u001B[38;5;241m=\u001B[39m XGB(\n\u001B[1;32m      2\u001B[0m     colsample_bytree\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.8\u001B[39m,\n\u001B[1;32m      3\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m     seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m11\u001B[39m\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m---> 10\u001B[0m xgb\u001B[38;5;241m.\u001B[39mfit(onehot_train_X,train_set_Y)\n\u001B[1;32m     12\u001B[0m xgb_predict_proba \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mpredict_proba(onehot_train_X)\n\u001B[1;32m     14\u001B[0m xgb_def_rate \u001B[38;5;241m=\u001B[39m xgb_predict_proba[:,\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1462\u001B[0m (\n\u001B[1;32m   1463\u001B[0m     model,\n\u001B[1;32m   1464\u001B[0m     metric,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1469\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[1;32m   1470\u001B[0m )\n\u001B[1;32m   1471\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[1;32m   1472\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[1;32m   1473\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1487\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[1;32m   1488\u001B[0m )\n\u001B[0;32m-> 1490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[1;32m   1491\u001B[0m     params,\n\u001B[1;32m   1492\u001B[0m     train_dmatrix,\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_num_boosting_rounds(),\n\u001B[1;32m   1494\u001B[0m     evals\u001B[38;5;241m=\u001B[39mevals,\n\u001B[1;32m   1495\u001B[0m     early_stopping_rounds\u001B[38;5;241m=\u001B[39mearly_stopping_rounds,\n\u001B[1;32m   1496\u001B[0m     evals_result\u001B[38;5;241m=\u001B[39mevals_result,\n\u001B[1;32m   1497\u001B[0m     obj\u001B[38;5;241m=\u001B[39mobj,\n\u001B[1;32m   1498\u001B[0m     custom_metric\u001B[38;5;241m=\u001B[39mmetric,\n\u001B[1;32m   1499\u001B[0m     verbose_eval\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   1500\u001B[0m     xgb_model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m   1501\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   1502\u001B[0m )\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[1;32m   1505\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m bst\u001B[38;5;241m.\u001B[39mupdate(dtrain, i, obj)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:1918\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dmatrix_features(dtrain)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1918\u001B[0m     _check_call(_LIB\u001B[38;5;241m.\u001B[39mXGBoosterUpdateOneIter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m   1919\u001B[0m                                             ctypes\u001B[38;5;241m.\u001B[39mc_int(iteration),\n\u001B[1;32m   1920\u001B[0m                                             dtrain\u001B[38;5;241m.\u001B[39mhandle))\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1922\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#计算AUC\n",
    "fpr, tpr, thresh_lr = roc_curve(train_set_Y,xgb_def_rate)\n",
    "# 计算 AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# 计算 KS 统计量\n",
    "ks_statistic = np.max(tpr - fpr)\n",
    "print(f\"KS Statistic on Train Set: {ks_statistic}\")\n",
    "print(f\"AUC on Test Set: {roc_auc}\")\n",
    "\n",
    "# 测试-- begin\n",
    "# 使用训练好的模型进行预测\n",
    "test_predict_proba = xgb.predict_proba(onehot_test_X)[:, 1]\n",
    "# 真实标签\n",
    "true_labels = test_set_Y\n",
    "# 计算 ROC 曲线的各个点\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, test_predict_proba)\n",
    "# 计算 KS 统计量\n",
    "ks_statistic = np.max(tpr - fpr)\n",
    "# 计算 AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"KS Statistic on Test Set: {ks_statistic}\")\n",
    "print(f\"AUC on Test Set: {roc_auc}\")\n",
    "# 测试-- end\n",
    "\n",
    "# oot-- begin\n",
    "# 使用训练好的模型进行预测\n",
    "oot_predict_proba = xgb.predict_proba(onehot_oot_X)[:, 1]\n",
    "# 真实标签\n",
    "true_labels = oot_set_Y\n",
    "# 计算 ROC 曲线的各个点\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, oot_predict_proba)\n",
    "# 计算 KS 统计量\n",
    "ks_statistic = np.max(tpr - fpr)\n",
    "# 计算 AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"KS Statistic on OOT Set: {ks_statistic}\")\n",
    "print(f\"AUC on OOT Set: {roc_auc}\")\n",
    "# 测试-- end\n",
    "# print(toad.metrics.PSI(pred_train[:,1],pred_test))"
   ],
   "id": "7d377fb2a29c2bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:49:13.167468Z",
     "start_time": "2024-05-01T03:49:13.098848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(toad.metrics.PSI(xgb_def_rate,test_predict_proba))\n",
    "print(toad.metrics.PSI(xgb_def_rate,oot_predict_proba))\n",
    "print('--------')"
   ],
   "id": "62238368880300e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14727406984061786\n",
      "0.13892559495234413\n",
      "--------\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# print(calculate_psi(xgb_def_rate,test_predict_proba))\n",
    "# print(calculate_psi(xgb_def_rate,oot_predict_proba))\n",
    "buckets = 10\n",
    "expected_array = xgb_def_rate\n",
    "actual_array = oot_predict_proba\n",
    "# 将分数切割成分位数分箱\n",
    "breakpoints = np.linspace(0, 100, buckets + 1)\n",
    "breakpoints = np.percentile(expected_array, breakpoints)\n",
    "# 确保分箱边界的唯一性\n",
    "breakpoints = np.unique(breakpoints)\n",
    "print(breakpoints)\n",
    "\n",
    "# 使用分位数计算分箱后每个箱子的实际和预期人数\n",
    "expected_counts = np.histogram(expected_array, breakpoints)[0]\n",
    "actual_counts = np.histogram(actual_array, breakpoints)[0]\n",
    "\n",
    "# 计算每个箱子的占比\n",
    "expected_probs = expected_counts / expected_counts.sum()\n",
    "actual_probs = actual_counts / actual_counts.sum()\n",
    "\n",
    "# 处理0概率的情况，以避免0概率导致的计算错误\n",
    "actual_probs += np.finfo(float).eps\n",
    "expected_probs += np.finfo(float).eps\n",
    "\n",
    "# 计算PSI\n",
    "psi_values = (actual_probs - expected_probs) * np.log(actual_probs / expected_probs)\n",
    "psi = np.sum(psi_values)\n",
    "psi\n",
    "\n",
    "# oot_predict_proba"
   ],
   "id": "2b7f26ea76865b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 假设xgb是已经训练好的XGBoost模型\n",
    "# train_set_X是用于训练模型的特征数据集\n",
    "\n",
    "# 获取特征重要性并创建一个DataFrame\n",
    "feature_importances = pd.DataFrame(xgb.feature_importances_,\n",
    "                                   index=train_set_X.columns,\n",
    "                                   columns=['importance'])\n",
    "\n",
    "# 对特征重要性进行降序排序\n",
    "sorted_features = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 选择前30个最重要的特征\n",
    "top_30_features = sorted_features.head(30)\n",
    "\n",
    "# 打印结果\n",
    "top_30_features"
   ],
   "id": "91a8f8edeb211865",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.fill_between(fpr, fpr, tpr, color='grey', alpha=0.3, label='Area under curve')\n",
    "plt.plot([fpr[ks_statistic]], [tpr[ks_statistic]], marker='o', markersize=5, color=\"red\")\n",
    "plt.text(fpr[ks_statistic], tpr[ks_statistic], f'KS={ks_statistic:.2f}', fontsize=12, ha='right')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# 绘制KS曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(thresholds, tpr, label='TPR', color='blue')\n",
    "plt.plot(thresholds, fpr, label='FPR', color='green')\n",
    "plt.plot([thresholds[ks_statistic], thresholds[ks_statistic]], [fpr[ks_statistic], tpr[ks_statistic]], 'k--', color=\"red\")\n",
    "plt.fill_between(thresholds, fpr, tpr, where=tpr>fpr, color='grey', alpha=0.3)\n",
    "plt.gca().invert_xaxis()  # 阈值由高到低\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('KS Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2b40ee5e1a28502c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2ac05563afb6c9cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "46f762de61a42055",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "99dce6e62ae2bebb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
